---
layout: post
title: Homage to the Mechanical Turk
image: "/posts/RobotArm_0.jpg"
tags: [Arm, Animatronics, CV, AI]
---

As a group project, my team created an autonomous robot to play checkers against a human play or even itself. This robot features several enhancemnts that I worked heavily on, such as:
- Computer vision code that allows the camera to be moved varying distances from the board, as well as rotated
- Animatronics that work in tandem with a voice clone of our class TA
- A custom built checkers game that features 5 game modes, and integrates with the robot arm movement
- An electromagent that picks up and drops pieces on command

<a href="https://github.com/JaredBaileyDuke/checkers-bot" target="_blank">Checkers Robot GitHub Repo</a>

### Additional Details
<a href="https://docs.google.com/document/d/10xn5eTtT8dCTDdlVrdTq22X1PhowyuRzMgsAVY1DUzs/edit?usp=sharing" target="_blank">Research Paper</a>
<a href="https://docs.google.com/document/d/1FMohz3AauILTVf_g_xqXghDPm8sRMKJ1lJ5e8vT5N2g/edit?tab=t.0" target="_blank">Write Up</a>

### Video Preview
[![Checkers Robot](https://img.youtube.com/vi/Y9SKYIrPti8&t/sddefault.jpg)](https://www.youtube.com/watch?v=Y9SKYIrPti8&t)

___

# Table of Contents

- [Computer Vision](#cv)
- [Animatronics & Voice Clone](#animatronics)
- [Checkers Game](#checkers)

___

# Computer Vision <a name="cv"></a>
![alt text](/img/posts/CV_0.jpg "Computer Vision")

The integration of computer vision allows for ease in the robot playing against a human opponent. The video capture allows for the game memory to be updated with the current board layout.

Computer vision utilizes a live video feed from a camera on a stand that is detached from the board. This allows for different camera locations and rotations when compared to the board. This detachment creates the need for capture of not only piece locations, but also board location and orientation. This was done using 4 April Tags, where only 3 are required and the last is used for redundancy.

An HSV filter with a contour capture is combined with the known board orientation. This allows for the identification of piece color, location, and king status.

# Animatronics & Voice Clone <a name="animatronics"></a>
![Animatronic Eyes](https://raw.githubusercontent.com/JaredLBailey/JaredLBailey.github.io/master/img/posts/Eyes-0.gif)

STL files were obtained from Will Cogley (animatronic eyes) and Fanki the Printer (model of daughters teeth). The printed output from Willâ€™s STL files did not fit properly, due to many issues with tolerances. This required multiple adjustments and reprints for proper function. The teeth mold was not designed for animatronic use, and was thus modified to allow for the desired movement by my teammate Kaelyn.

The animatronics were controlled using an arduino, and serial communication for mouth movement to sync with the voice clone.

Kent Yamamoto provided the voice for our robot. We recorded samples of Kent speaking complex sentences containing a large variety of English phonemes in various parts of words and sentences. This captured required parts of speech to effectively mimic natural language. We also recorded Kent providing fluid language using intuitive speech, so that our cloned voice would have a realistic feel.

The cloned voice produced over 50 pre-recorded sayings, and can be accessed through API by calling a Local LLM (Llamafile) or ChatGPT, and ElevenLabs for live interaction.

# Checkers Game <a name="checkers"></a>
[![Human Plays Robot](https://img.youtube.com/vi/cr42X2ZvtG8&t/sddefault.jpg)](https://www.youtube.com/watch?v=cr42X2ZvtG8&t)

The game was built using Object Oriented Programming. Classes were created for the piece, board, and game. The piece class contained information about and methods concerning the location, color, king status, etc. The board class contained information about and methods concerning the available movements, current board layout, etc. The game class contained play for the human, random, prioritize jumps, LLM, and minimax actors.

My teammates designed and printed a custom end effector to hold an electromagnet, which in turn can pick up the pieces. I connected the electromagnet to a relay, and wrote code to have it seemlessly operate with the robot arm movements. The end effector makes use of an 8V electromagnet controlled by a 5V wired relay, as 5V was not sufficient to lift the checkers pieces consistently.

While playing checkers, there are four main actions the robot can perform. The robot can move a piece from one square to the next, move a piece off the board after a jump or kinging occurs, add a king to the board, or move out of the way of the board in order to allow a human turn without obstruction. Motion and path planning is integrated with other parts (electromagnet, voice clone, animatronics, and camera) to allow for proper operation of the entire robot.
